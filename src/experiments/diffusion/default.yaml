# ------------------------------------------------------------------------------
# DIFFUSION MODEL CONFIGURATION
# ------------------------------------------------------------------------------
# Default configuration for diffusion model experiments.
#
# This file defines the default settings for training and generation modes.
# ------------------------------------------------------------------------------

experiment: diffusion
mode: train # Options: train, generate

# ------------------------------------------------------------------------------
# COMPUTE CONFIGURATION
# ------------------------------------------------------------------------------
# Device and reproducibility settings used across all modes

compute:
  device: cuda # Options: cuda, cpu, auto
  seed: 0 # Random seed for reproducibility (null to disable)

# ------------------------------------------------------------------------------
# LOGGING CONFIGURATION
# ------------------------------------------------------------------------------
# Application-level logging settings (not to be confused with metrics logging)

logging:
  console_level: INFO # Console logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  file_level: DEBUG # File logging level (can be more verbose than console)
  format: "%(asctime)s | %(name)s | %(levelname)s | %(message)s" # Log message format string
  date_format: "%Y-%m-%d %H:%M:%S" # Timestamp format in log messages
  timezone: local # Timezone for timestamps: UTC, local, or IANA timezone (e.g., Asia/Tokyo)

  # Optional: Module-specific log levels
  # module_levels:
  #   src.experiments.diffusion.trainer: DEBUG
  #   src.base.trainer: INFO

  # Metrics Logging Configuration
  metrics:
    csv:
      enabled: true # Set to true to enable CSV logging of metrics

    tensorboard:
      enabled: true # Set to true to enable TensorBoard
      flush_secs: 30 # Flush frequency in seconds
      log_images: true # Log confusion matrices, predictions, samples
      log_histograms: true # Log weight/gradient histograms (expensive)
      log_graph: true # Log model computational graph (once at start)

# ------------------------------------------------------------------------------
# MODEL CONFIGURATION
# ------------------------------------------------------------------------------
# Model architecture, diffusion process, and conditioning settings

model:
  # Architecture: U-Net structure and channels
  architecture:
    image_size: 40 # Size of generated images (H-W)
    in_channels: 3 # Number of input channels (3 for RGB)
    model_channels: 64 # Base number of U-Net channels
    channel_multipliers: [1, 2, 4] # Channel multipliers per stage
    use_attention: [false, false, true] # Attention at each stage

  # Diffusion: Noise scheduling and timesteps
  diffusion:
    num_timesteps: 1000 # Number of diffusion timesteps
    beta_schedule: cosine # Options: linear, cosine, quadratic, sigmoid
    beta_start: 0.0001 # Starting beta value
    beta_end: 0.02 # Ending beta value

  # Conditioning: Class conditioning for guided generation
  conditioning:
    type: class # Options: null (unconditional), "class" (class-conditional)
    num_classes: 2 # Number of classes (required if type="class")
    class_dropout_prob: 0.1 # Dropout for classifier-free guidance

# ------------------------------------------------------------------------------
# DATA CONFIGURATION
# ------------------------------------------------------------------------------
# Dataset paths, loading, and augmentation settings

data:
  # Split file: Path to train/val split JSON generated by data_preparation experiment
  split_file: "outputs/splits/train_val_split.json"

  # Loading: DataLoader parameters
  loading:
    batch_size: 8 # Batch size for training/generation
    num_workers: 4 # Number of data loading workers
    pin_memory: true # Pin memory for faster GPU transfer
    shuffle_train: true # Shuffle training data
    drop_last: false # Drop incomplete batches

  # Augmentation: Data augmentation settings
  augmentation:
    horizontal_flip: true # Random horizontal flip
    rotation_degrees: 15 # Random rotation (0 to disable)
    color_jitter: # Color jitter augmentation
      enabled: false # Enable color jitter
      strength: 0.1 # Jitter strength (0.0-1.0)

# ------------------------------------------------------------------------------
# OUTPUT CONFIGURATION
# ------------------------------------------------------------------------------
# Output directory structure

output:
  base_dir: outputs/diffusion # Base output directory
  subdirs: # Subdirectories for different outputs
    logs: logs # Logging files
    checkpoints: checkpoints # Model checkpoints
    samples: samples # Training samples
    generated: generated # Generated images
    tensorboard: tensorboard # TensorBoard event logs

# ------------------------------------------------------------------------------
# TRAINING MODE CONFIGURATION
# ------------------------------------------------------------------------------
# Only used when mode: train

training:
  # Core Training Parameters
  epochs: 500 # Number of training epochs

  # Optimizer: Optimization algorithm and parameters
  optimizer:
    type: adam # Options: adam, adamw
    learning_rate: 0.0001 # Learning rate
    weight_decay: 0.0 # L2 regularization
    betas: [0.9, 0.999] # Adam beta parameters
    gradient_clip_norm: null # Max gradient norm (null to disable)

  # Scheduler: Learning rate scheduling
  scheduler:
    type: cosine # Options: cosine, step, plateau, null (none)
    T_max: auto # For cosine (auto - epochs)
    eta_min: 1.0e-6 # For cosine (minimum LR)

  # EMA: Exponential Moving Average
  ema:
    enabled: true # Use EMA for better sample quality
    decay: 0.9999 # EMA decay rate

  # Checkpointing: Model checkpoint saving
  checkpointing:
    save_frequency: 50 # Save every N epochs
    save_optimizer: true # Include optimizer state in checkpoints
    save_best_only: false # Save all checkpoints
    save_latest: false # Always save latest_checkpoint.pth after every epoch

  # Validation: Validation during training
  validation:
    enabled: true # Run validation
    frequency: 50 # Validate every N epochs
    metric: loss # Metric to monitor

  # Visualization: Sample generation during training
  visualization:
    enabled: true # Master switch: if false, no sampling occurs at all
    num_samples: 8 # Number of samples to generate (shared by all below)
    guidance_scale: 3.0 # Classifier-free guidance scale (shared by all below)
    log_images_interval: 50 # Save sample grid every N epochs (null to disable)
    log_sample_comparison_interval: 50 # Save quality comparison every N epochs (null to disable)
    log_denoising_interval: 50 # Save denoising process every N epochs (null to disable)

  # Performance: Performance optimization settings
  performance:
    use_amp: true # Automatic mixed precision (CUDA only)
    use_tf32: true # Enable TF32 on Ampere+ GPUs
    cudnn_benchmark: true # cuDNN benchmark mode
    compile_model: true # Use torch.compile (PyTorch 2.0+)

  # Resume: Resume training from checkpoint
  resume:
    enabled: false # Enable resume training
    checkpoint: null # Path to checkpoint (required if enabled)
    reset_optimizer: false # Reset optimizer state
    reset_scheduler: false # Reset scheduler state

# ------------------------------------------------------------------------------
# GENERATION MODE CONFIGURATION
# ------------------------------------------------------------------------------
# Only used when mode: generate

generation:
  checkpoint: null # Path to trained model checkpoint (required)

  # Sampling: Generation parameters
  sampling:
    num_samples: 100 # Total number of samples to generate
    batch_size: 50 # Max samples per forward pass (prevents OOM for large num_samples)
    guidance_scale: 3.0 # Classifier-free guidance scale (>= 0.0)
    use_ema: true # Use EMA weights if available
    ema_decay: 0.9999 # EMA decay rate for generation (should match training.ema.decay)

  # Output: Generation output settings
  output:
    save_individual: true # Save individual sample images
    save_grid: true # Save samples as grid image
    grid_nrow: 10 # Number of samples per row in grid
