# ------------------------------------------------------------------------------
# CLASSIFIER CONFIGURATION
# ------------------------------------------------------------------------------
# Default configuration for training image classification models (ResNet, InceptionV3)
# ------------------------------------------------------------------------------

experiment: classifier # Identifies the experiment type
mode: train # Options: train, evaluate

# ------------------------------------------------------------------------------
# COMPUTE CONFIGURATION
# ------------------------------------------------------------------------------
# Device and reproducibility settings used across all modes

compute:
  device: cuda # Options: cuda, cpu, auto
  seed: null # Random seed for reproducibility (null for random)

# ------------------------------------------------------------------------------
# LOGGING CONFIGURATION
# ------------------------------------------------------------------------------
# Application-level logging settings (not to be confused with metrics logging)

logging:
  # Console logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  console_level: INFO

  # File logging level (can be more verbose than console)
  file_level: DEBUG

  # Log message format string
  format: "%(asctime)s | %(name)s | %(levelname)s | %(message)s"

  # Timestamp format in log messages
  date_format: "%Y-%m-%d %H:%M:%S"

  # Timezone for timestamps: UTC, local, or IANA timezone (e.g., Asia/Tokyo)
  timezone: UTC

  # Optional: Module-specific log levels
  # module_levels:
  #   src.experiments.classifier.trainer: DEBUG
  #   src.base.trainer: INFO
  #   src.utils.device: WARNING

  # Metrics Logging Configuration
  metrics:
    csv:
      enabled: true

    tensorboard:
      enabled: true # Set to true to enable TensorBoard
      flush_secs: 30 # Flush frequency in seconds
      log_images: true # Log generated samples, denoising sequences
      log_histograms: false # Log weight/gradient histograms (expensive)
      log_graph: false # Log model computational graph (once at start)

# ------------------------------------------------------------------------------
# MODEL CONFIGURATION
# ------------------------------------------------------------------------------
# Model architecture, initialization, and regularization settings

model:
  architecture:
    name: resnet50 # Options: resnet50, resnet101, resnet152, inceptionv3
    num_classes: 2 # Number of output classes (e.g., 2 for binary, 10 for CIFAR-10)

  initialization:
    pretrained: true # Use ImageNet pretrained weights (recommended for transfer learning)
    freeze_backbone: false # Freeze feature extraction layers (true = classifier head only)
    trainable_layers: null # List of layer patterns to unfreeze (InceptionV3 only)

  regularization:
    dropout: 0.5 # Only for InceptionV3

# ------------------------------------------------------------------------------
# DATA CONFIGURATION
# ------------------------------------------------------------------------------
# Dataset paths, loading parameters, and preprocessing

data:
  paths:
    train: data/train # Path to training dataset (structure: train/<class>/<images>)
    val: data/val # Path to validation dataset (structure: val/<class>/<images>)

  loading:
    batch_size: 32 # Samples per batch (larger = more GPU memory, more stable gradients)
    num_workers: 4 # Parallel data loading workers (0 = single-process)
    pin_memory: true # Faster CPU-to-GPU transfer (set true when using CUDA)
    shuffle_train: true # Shuffle training data each epoch
    drop_last: false # Drop incomplete last batch

  preprocessing:
    image_size: 256 # Resize shorter side to this before cropping
    crop_size: 224 # Final crop size fed to model (224 for ResNet, 299 for InceptionV3)
    normalize: imagenet # Options: imagenet, cifar10, none, null

  augmentation:
    horizontal_flip: true # Random horizontal flip (50% probability)
    rotation_degrees: 0 # Random rotation range in degrees (0 to disable)
    color_jitter:
      enabled: false # Enable color jitter augmentation
      brightness: 0.2 # Brightness adjustment range ±20%
      contrast: 0.2 # Contrast adjustment range ±20%
      saturation: 0.2 # Saturation adjustment range ±20%
      hue: 0.1 # Hue shift range ±0.1 (fraction of hue circle)

# ------------------------------------------------------------------------------
# OUTPUT CONFIGURATION
# ------------------------------------------------------------------------------
# Output directory structure

output:
  base_dir: outputs # Base directory for all experiment artifacts
  subdirs:
    logs: logs # Training logs and metrics
    checkpoints: checkpoints # Model checkpoint files (.pth)
    tensorboard: tensorboard # TensorBoard event logs

# ------------------------------------------------------------------------------
# TRAINING CONFIGURATION
# ------------------------------------------------------------------------------
# Only used when mode=train

training:
  epochs: 100 # Total training epochs

  # Optimizer: Optimization algorithm and parameters
  optimizer:
    type: adam # Options: adam, sgd, adamw
    learning_rate: 0.001 # Initial learning rate
    weight_decay: 0.0001 # L2 regularization strength
    gradient_clip_norm: null # Max gradient norm for clipping (null to disable)

  # Scheduler: Learning rate scheduling
  scheduler:
    type: cosine # Options: cosine, step, plateau, none
    T_max: auto # For cosine (auto sets to epochs)
    eta_min: 0.000001 # For cosine

  # Checkpointing: Model checkpoint saving
  checkpointing:
    save_frequency: 10 # Save every N epochs
    save_best_only: true # Only save when validation metric improves
    save_optimizer: true # Include optimizer state for exact resume
    save_latest: true # Always save latest_checkpoint.pth after every epoch

  # Validation: Validation during training
  validation:
    enabled: true # Enable validation during training
    frequency: 1 # Validate every N epochs
    metric: accuracy # Options: accuracy, loss
    early_stopping_patience: null # Epochs to wait before early stopping (null to disable)

  # Performance: Performance optimization settings
  performance:
    use_amp: false # Automatic mixed precision (CUDA only)
    use_tf32: true # Enable TF32 on Ampere+ GPUs
    cudnn_benchmark: true # cuDNN benchmark mode
    compile_model: false # Use torch.compile (PyTorch 2.0+)

  # Resume: Resume training from checkpoint
  resume:
    enabled: false # Enable resumption from checkpoint
    checkpoint: null # Path to checkpoint (required if enabled)
    reset_optimizer: false # Reset optimizer state when resuming
    reset_scheduler: false # Reset LR scheduler when resuming
