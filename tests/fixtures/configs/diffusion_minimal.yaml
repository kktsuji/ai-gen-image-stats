experiment: diffusion
mode: train

compute:
  device: cpu
  seed: 42

model:
  architecture:
    image_size: 32
    in_channels: 3
    model_channels: 32
    channel_multipliers: [1, 2]
    use_attention: [false, true]
  diffusion:
    num_timesteps: 100
    beta_schedule: linear
    beta_start: 0.0001
    beta_end: 0.02
  conditioning:
    type: null
    num_classes: null
    class_dropout_prob: 0.1

data:
  paths:
    train: data/train
    val: null
  loading:
    batch_size: 2
    num_workers: 0
    pin_memory: false
    shuffle_train: true
    drop_last: false
  augmentation:
    horizontal_flip: false
    rotation_degrees: 0
    color_jitter:
      enabled: false
      strength: 0.1

output:
  base_dir: outputs
  subdirs:
    logs: logs
    checkpoints: checkpoints
    samples: samples
    generated: generated

training:
  epochs: 2
  optimizer:
    type: adam
    learning_rate: 0.001
    weight_decay: 0.0
    betas: [0.9, 0.999]
    gradient_clip_norm: null
  scheduler:
    type: null
  ema:
    enabled: false
    decay: 0.9999
  checkpointing:
    save_frequency: 1
    save_best_only: false
    save_optimizer: true
  validation:
    enabled: false
    frequency: 1
    metric: loss
  visualization:
    enabled: false
    interval: 10
    num_samples: 4
    guidance_scale: 1.0
  performance:
    use_amp: false
    use_tf32: false
    cudnn_benchmark: false
    compile_model: false
  resume:
    enabled: false
    checkpoint: null
    reset_optimizer: false
    reset_scheduler: false

generation:
  checkpoint: null
  sampling:
    num_samples: 10
    guidance_scale: 1.0
    use_ema: false
  output:
    save_individual: true
    save_grid: false
    grid_nrow: 5
