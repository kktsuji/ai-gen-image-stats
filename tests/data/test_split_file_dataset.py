"""Tests for SplitFileDataset

This module tests the SplitFileDataset class that loads images
from a split JSON file generated by the data_preparation experiment.
"""

import json
from pathlib import Path

import pytest
import torch
from PIL import Image
from torchvision import transforms

from src.data.datasets import SplitFileDataset, get_dataset

# ============================================================================
# Helper Functions
# ============================================================================


def _create_split_json(tmp_path, image_dir, num_train=4, num_val=2):
    """Create a mock split JSON file with matching images.

    Args:
        tmp_path: Temporary directory
        image_dir: Directory to create mock images in
        num_train: Number of training samples per class
        num_val: Number of validation samples per class

    Returns:
        Path to the split JSON file
    """
    # Create image directories
    class0_dir = image_dir / "class0"
    class1_dir = image_dir / "class1"
    class0_dir.mkdir(parents=True, exist_ok=True)
    class1_dir.mkdir(parents=True, exist_ok=True)

    train_entries = []
    val_entries = []

    # Create class 0 images
    for i in range(num_train):
        img_path = class0_dir / f"img_{i:03d}.png"
        Image.new("RGB", (32, 32), color="green").save(img_path)
        train_entries.append({"path": str(img_path), "label": 0})

    for i in range(num_val):
        img_path = class0_dir / f"val_img_{i:03d}.png"
        Image.new("RGB", (32, 32), color="green").save(img_path)
        val_entries.append({"path": str(img_path), "label": 0})

    # Create class 1 images
    for i in range(num_train):
        img_path = class1_dir / f"img_{i:03d}.png"
        Image.new("RGB", (32, 32), color="red").save(img_path)
        train_entries.append({"path": str(img_path), "label": 1})

    for i in range(num_val):
        img_path = class1_dir / f"val_img_{i:03d}.png"
        Image.new("RGB", (32, 32), color="red").save(img_path)
        val_entries.append({"path": str(img_path), "label": 1})

    split_data = {
        "metadata": {
            "created_at": "2026-02-21T12:00:00",
            "seed": 42,
            "train_ratio": 0.8,
            "total_samples": len(train_entries) + len(val_entries),
            "train_samples": len(train_entries),
            "val_samples": len(val_entries),
            "classes": {"class0": 0, "class1": 1},
            "class_samples": {
                "class0": {
                    "total": num_train + num_val,
                    "train": num_train,
                    "val": num_val,
                },
                "class1": {
                    "total": num_train + num_val,
                    "train": num_train,
                    "val": num_val,
                },
            },
            "source_paths": {
                "class0": str(class0_dir),
                "class1": str(class1_dir),
            },
        },
        "train": train_entries,
        "val": val_entries,
    }

    split_file = tmp_path / "split.json"
    with open(split_file, "w") as f:
        json.dump(split_data, f, indent=2)

    return str(split_file)


# ============================================================================
# Unit Tests - Fast, minimal I/O
# ============================================================================


@pytest.mark.unit
class TestSplitFileDatasetInit:
    """Test SplitFileDataset initialization."""

    def test_invalid_split_key_raises(self, tmp_path):
        """Test that invalid split key raises ValueError."""
        # Create a minimal split JSON
        split_file = tmp_path / "split.json"
        split_data = {
            "metadata": {"classes": {"a": 0}},
            "train": [{"path": "x.png", "label": 0}],
            "val": [{"path": "y.png", "label": 0}],
        }
        with open(split_file, "w") as f:
            json.dump(split_data, f)

        with pytest.raises(ValueError, match="Invalid split"):
            SplitFileDataset(split_file=str(split_file), split="test")

    def test_missing_file_raises(self):
        """Test that missing split file raises FileNotFoundError."""
        with pytest.raises(FileNotFoundError):
            SplitFileDataset(split_file="/nonexistent/split.json", split="train")

    def test_empty_split_raises(self, tmp_path):
        """Test that empty split raises ValueError."""
        split_file = tmp_path / "split.json"
        split_data = {
            "metadata": {"classes": {"a": 0}},
            "train": [],
            "val": [{"path": "x.png", "label": 0}],
        }
        with open(split_file, "w") as f:
            json.dump(split_data, f)

        with pytest.raises(ValueError, match="No samples found"):
            SplitFileDataset(split_file=str(split_file), split="train")


# ============================================================================
# Component Tests - With actual image loading
# ============================================================================


@pytest.mark.component
class TestSplitFileDatasetLoading:
    """Test SplitFileDataset data loading functionality."""

    def test_load_train_split(self, tmp_path):
        """Test loading the training split."""
        split_file = _create_split_json(
            tmp_path, tmp_path / "images", num_train=3, num_val=1
        )
        dataset = SplitFileDataset(split_file=split_file, split="train")

        assert len(dataset) == 6  # 3 per class * 2 classes

    def test_load_val_split(self, tmp_path):
        """Test loading the validation split."""
        split_file = _create_split_json(
            tmp_path, tmp_path / "images", num_train=3, num_val=2
        )
        dataset = SplitFileDataset(split_file=split_file, split="val")

        assert len(dataset) == 4  # 2 per class * 2 classes

    def test_getitem_returns_image_and_label(self, tmp_path):
        """Test that __getitem__ returns (image, label) tuple."""
        split_file = _create_split_json(tmp_path, tmp_path / "images")
        dataset = SplitFileDataset(split_file=split_file, split="train")

        item = dataset[0]
        assert isinstance(item, tuple)
        assert len(item) == 2
        image, label = item
        assert isinstance(image, Image.Image)
        assert isinstance(label, int)

    def test_getitem_with_transform(self, tmp_path):
        """Test that transforms are applied."""
        split_file = _create_split_json(tmp_path, tmp_path / "images")
        transform = transforms.Compose([transforms.Resize(16), transforms.ToTensor()])
        dataset = SplitFileDataset(
            split_file=split_file, split="train", transform=transform
        )

        image, label = dataset[0]
        assert isinstance(image, torch.Tensor)
        assert image.shape == (3, 16, 16)

    def test_return_labels_false(self, tmp_path):
        """Test that return_labels=False returns only image."""
        split_file = _create_split_json(tmp_path, tmp_path / "images")
        dataset = SplitFileDataset(
            split_file=split_file, split="train", return_labels=False
        )

        item = dataset[0]
        assert isinstance(item, Image.Image)

    def test_classes_property(self, tmp_path):
        """Test classes property returns correct class names."""
        split_file = _create_split_json(tmp_path, tmp_path / "images")
        dataset = SplitFileDataset(split_file=split_file, split="train")

        classes = dataset.classes
        assert "class0" in classes
        assert "class1" in classes
        assert len(classes) == 2

    def test_class_to_idx_property(self, tmp_path):
        """Test class_to_idx property."""
        split_file = _create_split_json(tmp_path, tmp_path / "images")
        dataset = SplitFileDataset(split_file=split_file, split="train")

        c2i = dataset.class_to_idx
        assert c2i["class0"] == 0
        assert c2i["class1"] == 1

    def test_get_class_counts(self, tmp_path):
        """Test get_class_counts returns correct counts."""
        split_file = _create_split_json(
            tmp_path, tmp_path / "images", num_train=3, num_val=1
        )
        dataset = SplitFileDataset(split_file=split_file, split="train")

        counts = dataset.get_class_counts()
        assert counts["class0"] == 3
        assert counts["class1"] == 3

    def test_samples_property(self, tmp_path):
        """Test samples property returns (path, label) tuples."""
        split_file = _create_split_json(tmp_path, tmp_path / "images")
        dataset = SplitFileDataset(split_file=split_file, split="train")

        samples = dataset.samples
        assert len(samples) == len(dataset)
        for path, label in samples:
            assert isinstance(path, str)
            assert isinstance(label, int)

    def test_targets_property(self, tmp_path):
        """Test targets property returns list of labels."""
        split_file = _create_split_json(tmp_path, tmp_path / "images")
        dataset = SplitFileDataset(split_file=split_file, split="train")

        targets = dataset.targets
        assert len(targets) == len(dataset)
        assert all(isinstance(t, int) for t in targets)

    def test_missing_image_raises(self, tmp_path):
        """Test that missing image file raises FileNotFoundError."""
        split_file = tmp_path / "split.json"
        split_data = {
            "metadata": {"classes": {"a": 0}},
            "train": [{"path": str(tmp_path / "nonexistent.png"), "label": 0}],
            "val": [],
        }
        with open(split_file, "w") as f:
            json.dump(split_data, f)

        dataset = SplitFileDataset(split_file=str(split_file), split="train")
        with pytest.raises(FileNotFoundError, match="Image file not found"):
            dataset[0]


# ============================================================================
# Unit Tests - get_dataset factory
# ============================================================================


@pytest.mark.unit
class TestGetDatasetFactory:
    """Test get_dataset factory with splitfile type."""

    def test_splitfile_type_creates_dataset(self, tmp_path):
        """Test that 'splitfile' creates a SplitFileDataset."""
        split_file = _create_split_json(tmp_path, tmp_path / "images")
        dataset = get_dataset("splitfile", split_file=split_file, split="train")
        assert isinstance(dataset, SplitFileDataset)

    def test_unknown_type_raises(self):
        """Test that unknown dataset type raises ValueError."""
        with pytest.raises(ValueError, match="Unknown dataset type"):
            get_dataset("unknown", root="/tmp")
